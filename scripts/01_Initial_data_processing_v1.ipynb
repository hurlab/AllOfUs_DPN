{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "3Dd6x1AMMj2m"
      },
      "outputs": [],
      "source": [
        "# Load the necessary libraries\n",
        "library(tictoc);library(glue);library(googleCloudStorageR);library(googleAuthR);library(dplyr);library(tidyverse);\n",
        "library(bigrquery);library(stringr);library(ggplot2);library(gridExtra);library(readr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7TB0enazMj2n"
      },
      "outputs": [],
      "source": [
        "# tic(\"Total person data loading time\")\n",
        "\n",
        "# # This query represents dataset \"All_participants_dataset_022725\" for domain \"person\" and was generated for All of Us Controlled Tier Dataset v8\n",
        "dataset_46654386_person_sql <- paste(\"\n",
        "    SELECT\n",
        "        person.person_id,\n",
        "        person.gender_concept_id,\n",
        "        p_gender_concept.concept_name as gender,\n",
        "        person.birth_datetime as date_of_birth,\n",
        "        person.race_concept_id,\n",
        "        p_race_concept.concept_name as race,\n",
        "        person.ethnicity_concept_id,\n",
        "        p_ethnicity_concept.concept_name as ethnicity,\n",
        "        person.sex_at_birth_concept_id,\n",
        "        p_sex_at_birth_concept.concept_name as sex_at_birth,\n",
        "        person.self_reported_category_concept_id,\n",
        "        p_self_reported_category_concept.concept_name as self_reported_category\n",
        "    FROM\n",
        "        `person` person\n",
        "    LEFT JOIN\n",
        "        `concept` p_gender_concept\n",
        "            ON person.gender_concept_id = p_gender_concept.concept_id\n",
        "    LEFT JOIN\n",
        "        `concept` p_race_concept\n",
        "            ON person.race_concept_id = p_race_concept.concept_id\n",
        "    LEFT JOIN\n",
        "        `concept` p_ethnicity_concept\n",
        "            ON person.ethnicity_concept_id = p_ethnicity_concept.concept_id\n",
        "    LEFT JOIN\n",
        "        `concept` p_sex_at_birth_concept\n",
        "            ON person.sex_at_birth_concept_id = p_sex_at_birth_concept.concept_id\n",
        "    LEFT JOIN\n",
        "        `concept` p_self_reported_category_concept\n",
        "            ON person.self_reported_category_concept_id = p_self_reported_category_concept.concept_id\", sep=\"\")\n",
        "\n",
        "# Formulate a Cloud Storage destination path for the data exported from BigQuery.\n",
        "# NOTE: By default data exported multiple times on the same day will overwrite older copies.\n",
        "#       But data exported on a different days will write to a new location so that historical\n",
        "#       copies can be kept as the dataset definition is changed.\n",
        "\n",
        "# If you want to read the data, you don't have any line in this chunk again except this path.\n",
        "# Make sure the date is the same as where the data was intially saved.\n",
        "#--------------------------------------------\n",
        "person_46654386_path <- file.path(\n",
        "  Sys.getenv(\"WORKSPACE_BUCKET\"),\n",
        "  \"bq_exports\",\n",
        "  Sys.getenv(\"OWNER_EMAIL\"),\n",
        "  \"20250303\",\n",
        "  \"person_46654386\",\n",
        "  \"person_46654386_*.csv\")\n",
        "message(str_glue('The data will be written to {person_46654386_path}. Use this path when reading ',\n",
        "                 'the data into your notebooks in the future.'))\n",
        "#--------------------------------------------\n",
        "# # Perform the query and export the dataset to Cloud Storage as CSV files.\n",
        "# # NOTE: You only need to run `bq_table_save` once. After that, you can\n",
        "# #       just read data from the CSVs in Cloud Storage.\n",
        "bq_table_save(\n",
        "  bq_dataset_query(Sys.getenv(\"WORKSPACE_CDR\"), dataset_46654386_person_sql, billing = Sys.getenv(\"GOOGLE_PROJECT\")),\n",
        "  person_46654386_path,\n",
        "  destination_format = \"CSV\")\n",
        "\n",
        "toc()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "km6HiaWIMj2o"
      },
      "outputs": [],
      "source": [
        "# Read the data directly from Cloud Storage into memory.\n",
        "# NOTE: Alternatively you can `gsutil -m cp {person_46654386_path}` to copy these files\n",
        "#       to the Jupyter disk.\n",
        "tic(\"Total persons data loading time\") #Start overall time\n",
        "read_bq_export_from_workspace_bucket <- function(export_path) {\n",
        "  col_types <- cols(gender = col_character(), race = col_character(), ethnicity = col_character(), sex_at_birth = col_character(), self_reported_category = col_character())\n",
        "  bind_rows(\n",
        "    map(system2('gsutil', args = c('ls', export_path), stdout = TRUE, stderr = TRUE),\n",
        "        function(csv) {\n",
        "          message(str_glue('Loading {csv}.'))\n",
        "          chunk <- read_csv(pipe(str_glue('gsutil cat {csv}')), col_types = col_types, show_col_types = FALSE)\n",
        "          if (is.null(col_types)) {\n",
        "            col_types <- spec(chunk)\n",
        "          }\n",
        "          chunk\n",
        "        }))\n",
        "}\n",
        "dataset_46654386_person_df <- read_bq_export_from_workspace_bucket(person_46654386_path)\n",
        "\n",
        "dim(dataset_46654386_person_df)\n",
        "\n",
        "head(dataset_46654386_person_df, 5)\n",
        "toc()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e46MGLoUMj2o"
      },
      "outputs": [],
      "source": [
        "# rename the data\n",
        "person_dt <- dataset_46654386_person_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oI9f-slJMj2o"
      },
      "outputs": [],
      "source": [
        "# # This query represents dataset \"All_participants_dataset_022725\" for domain \"condition\" and was generated for\n",
        "# # All of Us Controlled Tier Dataset v8\n",
        "tic(\"Total conditions data loading time\") #Start overall time\n",
        "dataset_46654386_condition_sql <- paste(\"\n",
        "    SELECT\n",
        "        c_occurrence.person_id,\n",
        "        c_occurrence.condition_concept_id,\n",
        "        c_standard_concept.concept_name as standard_concept_name,\n",
        "        c_standard_concept.concept_code as standard_concept_code,\n",
        "        c_standard_concept.vocabulary_id as standard_vocabulary,\n",
        "        c_occurrence.condition_start_datetime,\n",
        "        c_occurrence.condition_end_datetime,\n",
        "        c_occurrence.condition_type_concept_id,\n",
        "        c_type.concept_name as condition_type_concept_name,\n",
        "        c_occurrence.condition_source_value,\n",
        "        c_occurrence.condition_source_concept_id,\n",
        "        c_source_concept.concept_name as source_concept_name,\n",
        "        c_source_concept.concept_code as source_concept_code,\n",
        "        c_source_concept.vocabulary_id as source_vocabulary,\n",
        "        c_occurrence.condition_status_source_value,\n",
        "        c_occurrence.condition_status_concept_id,\n",
        "        c_status.concept_name as condition_status_concept_name\n",
        "    FROM\n",
        "        `condition_occurrence` c_occurrence\n",
        "    LEFT JOIN\n",
        "        `concept` c_standard_concept\n",
        "            ON c_occurrence.condition_concept_id = c_standard_concept.concept_id\n",
        "    LEFT JOIN\n",
        "        `concept` c_type\n",
        "            ON c_occurrence.condition_type_concept_id = c_type.concept_id\n",
        "    LEFT JOIN\n",
        "        `concept` c_source_concept\n",
        "            ON c_occurrence.condition_source_concept_id = c_source_concept.concept_id\n",
        "    LEFT JOIN\n",
        "        `concept` c_status\n",
        "            ON c_occurrence.condition_status_concept_id = c_status.concept_id\n",
        "\")\n",
        "\n",
        "# Formulate a Cloud Storage destination path for the data exported from BigQuery.\n",
        "# NOTE: By default data exported multiple times on the same day will overwrite older copies.\n",
        "#       But data exported on a different days will write to a new location so that historical\n",
        "#       copies can be kept as the dataset definition is changed.\n",
        "#--------------------------------------------\n",
        "condition_46654386_path <- file.path(\n",
        "  Sys.getenv(\"WORKSPACE_BUCKET\"),\n",
        "  \"bq_exports\",\n",
        "  Sys.getenv(\"OWNER_EMAIL\"),\n",
        "  \"20250228\",\n",
        "  \"condition_46654386\",\n",
        "  \"condition_46654386_*.csv\")\n",
        "message(str_glue('The data will be written to {condition_46654386_path}. Use this path when reading ',\n",
        "                 'the data into your notebooks in the future.'))\n",
        "#--------------------------------------------\n",
        "# Perform the query and export the dataset to Cloud Storage as CSV files.\n",
        "# NOTE: You only need to run `bq_table_save` once. After that, you can\n",
        "#       just read data from the CSVs in Cloud Storage.\n",
        "bq_table_save(\n",
        "  bq_dataset_query(Sys.getenv(\"WORKSPACE_CDR\"), dataset_46654386_condition_sql, billing = Sys.getenv(\"GOOGLE_PROJECT\")),\n",
        "  condition_46654386_path,\n",
        "  destination_format = \"CSV\")\n",
        "toc()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JHEZHRBRMj2p"
      },
      "outputs": [],
      "source": [
        "# Function for condition data\n",
        "# Read the data directly from Cloud Storage into memory.\n",
        "# NOTE: Alternatively you can `gsutil -m cp {condition_022625_path}` to copy these files\n",
        "#       to the Jupyter disk.\n",
        "tic(\"Total conditions data loading time\") #Start overall time\n",
        "read_bq_export_condition <- function(export_path) {\n",
        "  col_types <- cols(\n",
        "    standard_concept_name = col_character(),\n",
        "    standard_concept_code = col_character(),\n",
        "    standard_vocabulary = col_character(),\n",
        "    condition_type_concept_name = col_character(),\n",
        "    condition_source_value = col_character(),\n",
        "    source_concept_name = col_character(),\n",
        "    source_concept_code = col_character(),\n",
        "    source_vocabulary = col_character(),\n",
        "    condition_status_source_value = col_character(),\n",
        "    condition_status_concept_name = col_character()\n",
        "  )\n",
        "  bind_rows(\n",
        "    map(system2('gsutil', args = c('ls', export_path), stdout = TRUE, stderr = TRUE),\n",
        "        function(csv) {\n",
        "          message(str_glue('Loading {csv}.'))\n",
        "          chunk <- read_csv(pipe(str_glue('gsutil cat {csv}')), col_types = col_types, show_col_types = FALSE)\n",
        "          if (is.null(col_types)) {\n",
        "            col_types <- spec(chunk)\n",
        "          }\n",
        "          chunk\n",
        "        }))\n",
        "}\n",
        "\n",
        "dataset_46654386_condition_df <- read_bq_export_condition(condition_46654386_path)\n",
        "\n",
        "dim(dataset_46654386_condition_df)\n",
        "\n",
        "head(dataset_46654386_condition_df, 5)\n",
        "toc()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cErGllZZMj2p"
      },
      "outputs": [],
      "source": [
        "head(dataset_46654386_condition_df, 20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c1e5Bs85Mj2q"
      },
      "outputs": [],
      "source": [
        "# Rename the data\n",
        "all_conditions_dt <- dataset_46654386_condition_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z3B8_kjbMj2q"
      },
      "outputs": [],
      "source": [
        "# Distinct number of conditions in the All of Us data\n",
        "n_distinct(all_conditions_dt$condition_concept_id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P75gFswqMj2r"
      },
      "outputs": [],
      "source": [
        "# Count occurrences of each condition_concept_id\n",
        "condition_counts <- all_conditions_dt %>%\n",
        "  group_by(condition_concept_id, standard_concept_name) %>%\n",
        "  summarise(count = n(), .groups = \"drop\")\n",
        "\n",
        "# View the result\n",
        "head(condition_counts,20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ixRXd6akMj2r"
      },
      "outputs": [],
      "source": [
        "nrow(condition_counts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kK6IIhAkMj2s"
      },
      "outputs": [],
      "source": [
        "# Filter the dataset for \"Pre diabetes\" with case insensitivity and handling hyphen variations\n",
        "pre_diabetes_conditions <- all_conditions_dt %>%\n",
        "  filter(str_detect(tolower(`standard_concept_name`), regex(\"pre[- ]?diabetes\", ignore_case = TRUE))) %>%\n",
        "  select(`person_id`, `condition_concept_id`, `standard_concept_name`)\n",
        "\n",
        "# Display the result\n",
        "print(pre_diabetes_conditions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QvAOo0VeMj2s"
      },
      "outputs": [],
      "source": [
        "# Distinct number of persons in the Pre-diabetes cohort\n",
        "n_distinct(pre_diabetes_conditions$person_id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1tJmIeCHMj2s"
      },
      "outputs": [],
      "source": [
        "# Filter dataset by diabetes condition\n",
        "# Copied concepts Ids from the data browser in the Researcher workbench\n",
        "concept_ids_diabetes <- c(201820,201826,4008576,4193704,442793,443732,4034964,37311673,37016349,443730,376065,\n",
        "                          4082346,192279,4044391,443731,4311708,376112,37016354,43530689,43531578,37017432,443767,\n",
        "                          443238,443733,321822,443729,201254,4174977,443412,376683,4029423,4226121,195771,435216,\n",
        "                          45757363,43530656,378743,4058243,4159742,45757435,45757277,43530690,376979,4221495,4175440,\n",
        "                          443727,42536605,4024659,37016768,40482801,37016348,4009303,37110593,4033942,43531616,4334884,\n",
        "                          35626904,380097,377821,380096,40484648,45757124,200687,42538169,43530685,377552,4099651,194700,\n",
        "                          35626070,45770928,45770830,37312218,4227210,45770881,443735,45769876,4226354,4222876,37018566,\n",
        "                          4196141,43531007,37017431,4202383,4048028,4226238,4114427,40485020,43531563,36717156,443734,\n",
        "                          4222415,4063043,4129519,43531010,4130162,4131908,37016767,45757129,318712,4029420,376114,45763583,\n",
        "                          45757079,45763584,36715571,439770,37016179,45770902,37311254,45757474,37311253,443012,4266637,\n",
        "                          35626764,4290822,4063042,43531009,43531008,35626039,201530,35626038,45757789,761051,45769832,\n",
        "                          4304377,4225656,37016180,4226798,4191611,4189418,4099214,4152858,37016355,761049,4200875,4338901,\n",
        "                          4095288,43531564,36674200,4234742,36714116,36674199,4140466,45769830,45773064,35626041,45770880,\n",
        "                          4223303,4145827,609096,35626042,40484649,45771064,609095,4227657,4225055,609114,45773688,609099,\n",
        "                          609101,4326434,4062686,609103,761048,37016357,37017430,4206115,4224254,4030664,42535540,45757508,\n",
        "                          43531653,4228112,42537681,4228443,201531,4128221,35626044,45757449,35626088,4171406,35626068,\n",
        "                          35626043,35626087,35626067,37016358,3655382,609116,3655383,4263902,609104,609119,4230254,43531651,\n",
        "                          609108,37311833,609105,36712687,609115,609118,609106,609117,609120,192691,37016356,45769873,\n",
        "                          37311832,609097,36712686,609107,609100,45757499,4178452,45757674,40480031,35626069,45769905,\n",
        "                          40480000,4099216,45757266,37018765,4147719,609102,45757507,37312204,609098,443592,609109,4245270,\n",
        "                          4143857,40482883,35626763,4215719,37312207,43531577,4143529,43531011,4177050,37018728,45757362,\n",
        "                          4016047,4060085,45757432,609112,602345,4144583,4062685,43531597,4054812,603318)\n",
        "# Pre-diabetes cohort added. They are the last two concept ids(37018196,44808385)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WT-oSpKCMj2s"
      },
      "outputs": [],
      "source": [
        "# Length of the concept IDs\n",
        "length(concept_ids_diabetes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SkcpSfozMj2s"
      },
      "outputs": [],
      "source": [
        "# Extract diabetes related conditions:\n",
        "# Extract all conditions containing \"diabetes\" or \"diabetics\"\n",
        "diabetes_conditions <- condition_counts %>%\n",
        "  filter(grepl(\"diabetes|diabetic\", standard_concept_name, ignore.case = TRUE) &\n",
        "          !(condition_concept_id %in% c(37018196,44808385,30968,4099334))\n",
        ")\n",
        "# View the first few rows\n",
        "head(diabetes_conditions, 20)\n",
        "\n",
        "# Count how many diabetes-related conditions were found\n",
        "nrow(diabetes_conditions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A1v_wvutMj2t"
      },
      "outputs": [],
      "source": [
        "# Compare the new concept ids with the existing ones I had\n",
        "new_diabetes_ids <- setdiff(diabetes_conditions$condition_concept_id, concept_ids_diabetes)\n",
        "print(new_diabetes_ids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gGPm1PdDMj2t"
      },
      "outputs": [],
      "source": [
        "# Unique condition concept IDs\n",
        "concept_ids_diabetes_2 <- unique(diabetes_conditions$condition_concept_id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B8pIoIYcMj2t"
      },
      "outputs": [],
      "source": [
        "length(unique(concept_ids_diabetes_2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "iq4Mj4U2Mj2t"
      },
      "outputs": [],
      "source": [
        "# Filter the dataset for rows where condition_concept_id is in the diabetes concept ID list\n",
        "diabetes_dataset <- all_conditions_dt %>%\n",
        "  filter(condition_concept_id %in% concept_ids_diabetes_2)\n",
        "\n",
        "# Display the first few rows of the filtered dataset\n",
        "head(diabetes_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PTjWdXGFMj2t"
      },
      "outputs": [],
      "source": [
        "length(unique(diabetes_dataset$condition_concept_id))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EQNz0hATMj2t"
      },
      "outputs": [],
      "source": [
        "# What is the dimension of the dataset\n",
        "dim(diabetes_dataset)\n",
        "\n",
        "# The distinct number of persons in the dataset\n",
        "n_distinct(diabetes_dataset$person_id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U6uQSZNzMj2t"
      },
      "outputs": [],
      "source": [
        "# Ensure one row per respondent by keeping only the first occurrence for each person_id\n",
        "diabetes_dataset_unique <- diabetes_dataset %>%\n",
        "  arrange(person_id, condition_start_datetime) %>%  # Sort by person_id and earliest date\n",
        "  group_by(person_id) %>%\n",
        "  slice(1) %>%  # Select the first occurrence per person (earliest date)\n",
        "  ungroup()\n",
        "dim(diabetes_dataset_unique)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LK2xPADIMj2t"
      },
      "outputs": [],
      "source": [
        "# group data by concept id and concept name\n",
        "# shows the number of participants that has different conditions\n",
        "temp1 <-\n",
        "  diabetes_dataset %>%\n",
        "  dplyr::group_by(condition_concept_id,standard_concept_name) %>%\n",
        "  dplyr::summarise(countp = n_distinct(person_id))\n",
        "temp1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZVTJTmWoMj2u"
      },
      "outputs": [],
      "source": [
        "# Extract diabetes related conditions:\n",
        "# Extract all conditions containing \"diabetic neuropathy\" or \"polyneuropathy\" or neuropathy or neuropathic or foot ulcer\n",
        "neuropathy_conditions <- condition_counts %>%\n",
        "   filter(grepl(\"diabetic neuropathy|polyneuropathy|neuropathy|neuropathic|diabetic foot ulcer\", standard_concept_name,\n",
        "   #filter(grepl(\"diabetic neuropathy|diabetic foot ulcer|neuropathy due to diabetes\", standard_concept_name,\n",
        "               ignore.case = TRUE))\n",
        "\n",
        "# View the first few rows\n",
        "head(neuropathy_conditions, 20)\n",
        "\n",
        "# Count how many diabetes-related conditions were found\n",
        "nrow(neuropathy_conditions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "ZQnjkqL5Mj2u"
      },
      "outputs": [],
      "source": [
        "# Check the un ique neuropathy list\n",
        "length(unique(neuropathy_conditions$standard_concept_name))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DKRj3-eKMj2u"
      },
      "outputs": [],
      "source": [
        "# Define the standard concept names to exclude\n",
        "to_be_excluded_conditions <- c(\n",
        "  \"Post-herpetic polyneuropathy\", \"Idiopathic peripheral autonomic neuropathy\", \"Mumps polyneuropathy\",\n",
        "  \"Toxic polyneuropathy\", \"Ischemic optic neuropathy\", \"Critical illness polyneuropathy\",\n",
        "  \"Polyneuropathy in collagen vascular disease\", \"Idiopathic peripheral neuropathy\",\n",
        "  \"Polyneuropathy associated with another disorder\", \"Hereditary peripheral neuropathy\",\n",
        "  \"Toxic optic neuropathy\", \"Inflammatory and toxic neuropathy\", \"Paraneoplastic neuropathy\",\n",
        "  \"Alcoholic polyneuropathy\", \"Idiopathic progressive polyneuropathy\", \"Hereditary sensory neuropathy\",\n",
        "  \"Nutritional optic neuropathy\", \"Chronic inflammatory demyelinating polyradiculoneuropathy\",\n",
        "  \"Polyneuropathy due to drug\", \"Femoral neuropathy\", \"Superficial peroneal neuropathy\",\n",
        "  \"Anterior ischemic optic neuropathy of right eye\", \"Entrapment neuropathy of right common peroneal nerve\",\n",
        "  \"Right common peroneal neuropathy at the fibular head\", \"Right deep peroneal neuropathy\",\n",
        "  \"Left common peroneal neuropathy at the fibular head\", \"Entrapment neuropathy of left sural nerve\",\n",
        "  \"Entrapment neuropathy of right plantar nerve\", \"Ulnar neuropathy of right arm\",\n",
        "  \"Ulnar neuropathy of left arm\", \"Retrobulbar neuropathy\", \"Deep peroneal neuropathy\",\n",
        "  \"Sensory polyneuropathy\", \"Familial non-neuropathic amyloidosis\", \"Ischemic peripheral neuropathy\",\n",
        "  \"Radial neuropathy\", \"Idiopathic trigeminal neuropathy\",\n",
        "  \"Neuropathy associated with dysproteinemias\", \"Neuropathy due to infection\",\n",
        "\"Idiopathic chronic neuropathy\",\n",
        "  \"Demyelinating sensorimotor neuropathy\", \"Neuropathy in benign monoclonal gammopathy\",\n",
        "  \"Motor neuropathy with multiple conduction block\", \"Neuropathy caused by chemical substance\",\n",
        "  \"Intercostal neuropathy\", \"Axonal sensorimotor neuropathy\", \"Arteritic ischemic optic neuropathy\",\n",
        "  \"Non-arteritic ischemic optic neuropathy\", \"Neuropathy associated with endocrine disorder\",\n",
        "  \"Neuropathy due to human immunodeficiency virus\", \"Neuropathy caused by organic substance\",\n",
        "  \"Compression neuropathy of upper limb\", \"Compression neuropathy of lower limb\",\n",
        "  \"Inflammatory neuropathy\", \"Peripheral demyelinating neuropathy\", \"Neuropathic spondylopathy\",\n",
        "  \"Polyneuropathy in herpes zoster\", \"Neuropathy in association with hereditary ataxia\",\n",
        "  \"Polyneuropathy in rheumatoid arthritis\", \"Polyneuropathy due to amyloidosis\",\n",
        "  \"Sarcoid neuropathy\", \"Serum neuropathy\", \"Polyneuropathy in disseminated lupus erythematosus\",\n",
        "  \"Polyradiculoneuropathy\", \"Mononeuropathy\", \"Hereditary motor and sensory neuropathy\",\n",
        "  \"Peripheral axonal neuropathy\", \"Sural neuropathy\", \"Vasculitic neuropathy\",\n",
        "  \"Drug induced optic neuropathy\", \"Tibial neuropathy\", \"Common peroneal neuropathy\",\n",
        "  \"Hereditary sensory-motor neuropathy, type I\", \"Amyloid polyneuropathy type I\",\n",
        "  \"Familial amyloid polyneuropathy\", \"Vitamin deficiency related neuropathy\",\n",
        "  \"Obturator neuropathy\", \"Lateral plantar neuropathy\", \"Mixed sensory-motor polyneuropathy\",\n",
        "  \"Sciatic neuropathy\", \"Anterior ischemic optic neuropathy\", \"Ulnar neuropathy\",\n",
        "  \"Upper brachial plexus neuropathy\",\n",
        "  \"Axonal neuropathy\", \"Median neuropathy\", \"Neuropathic ulcer\", \"Neuropathy\",\n",
        "  \"Acute herpes zoster neuropathy\", \"Motor polyneuropathy\", \"Entrapment neuropathy of upper limb\",\n",
        "  \"Sensory neuropathy\", \"Peripheral motor neuropathy\",\n",
        "  \"Peripheral neuropathy due to and following antineoplastic therapy\",\n",
        "  \"Distal hereditary motor neuropathy type 1\", \"Immune-mediated neuropathy\",\n",
        "  \"Ischemic optic neuropathy of right eye\", \"Ischemic optic neuropathy of left eye\",\n",
        "  \"Bilateral ischemic optic neuropathy of eyes\", \"Bilateral peripheral neuropathy of lower limbs\",\n",
        "  \"Cranial neuropathy due to Herpes zoster\", \"Idiopathic small fiber peripheral neuropathy\",\n",
        "  \"Peripheral neuropathy with sensorineural hearing impairment syndrome\",\n",
        "  \"Length-dependent peripheral neuropathy\", \"Autonomic neuropathy due to disorder of immune function\",\n",
        "  \"Peripheral sensory neuropathy\", \"Acute motor axonal neuropathy\", \"Neuropathy due to ionizing radiation\",\n",
        "  \"Left cervical root neuropathy\", \"Right common peroneal neuropathy\",\n",
        "  \"Left common peroneal neuropathy\", \"Right leg peripheral neuropathy\",\n",
        "  \"Left leg peripheral neuropathy\", \"Right radial neuropathy\", \"Left radial neuropathy\",\n",
        "  \"Chronic neuropathic pain\", \"Autonomic neuropathy due to endocrine disease\",\n",
        "  \"Chronic central neuropathic pain\", \"Radiation polyneuropathy\", \"Right cervical root neuropathy\",\n",
        "  \"Common peroneal neuropathy at the fibular head\", \"Acute inflammatory demyelinating polyneuropathy\",\n",
        "  \"Mononeuropathy of upper limb\", \"Mononeuropathy of lower limb\", \"Neuropathy of upper limb\",\n",
        "  \"Neuropathy of lower limb\", \"Suprascapular neuropathy\", \"Entrapment neuropathy of lower limb\",\n",
        "  \"Ulnar neuropathy at wrist\", \"Neuropathy due to vitamin B12 deficiency\",\n",
        "  \"Reflex neuropathic bladder\", \"Polyneuropathy due to systemic sclerosis\",\n",
        "  \"Peripheral neuropathy caused by toxin\", \"Peripheral neuropathy due to inflammation\",\n",
        "  \"Peripheral neuropathy due to metabolic disorder\",\n",
        "  \"Neuropathic pain due to radiation\",\"Lumbosacral plexus neuropathy\",\"Autonomic neuropathy\",\"Peripheral neuropathic pain\",\n",
        "  \"Neuropathic pain\",\"Polyneuropathy\", \"Secondary peripheral neuropathy\", \"Small fiber neuropathy\")\n",
        "# Filter out the unwanted conditions from neuropathy_conditions dataset\n",
        "filtered_neuropathy_conditions <- neuropathy_conditions %>%\n",
        "  filter(!(standard_concept_name %in% to_be_excluded_conditions))\n",
        "\n",
        "# View the updated dataset\n",
        "head(filtered_neuropathy_conditions)\n",
        "\n",
        "# Count the remaining conditions\n",
        "nrow(filtered_neuropathy_conditions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s8OWhtyDMj2u"
      },
      "outputs": [],
      "source": [
        "# unique(filtered_neuropathy_conditions$condition_concept_id)\n",
        "# # filter dataset by diabetic neuropathy\n",
        "concept_ids_dn2 <- unique(filtered_neuropathy_conditions$condition_concept_id)\n",
        "length(concept_ids_dn2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "914TrwUtMj2u"
      },
      "outputs": [],
      "source": [
        "# Filter the dataset for rows where condition_concept_id is in the diabetes concept ID list\n",
        "diabetic_neuro_dataset <- all_conditions_dt %>%\n",
        "  filter(condition_concept_id %in% concept_ids_dn2)\n",
        "\n",
        "# Display the first few rows of the filtered dataset\n",
        "head(diabetic_neuro_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qxGWai88Mj2v"
      },
      "outputs": [],
      "source": [
        "# Dinension and distinct number of diabetic neuropathy patients\n",
        "dim(diabetic_neuro_dataset)\n",
        "n_distinct(diabetic_neuro_dataset$person_id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "63brdiPEMj2v"
      },
      "outputs": [],
      "source": [
        "# Ensure one row per respondent by keeping only the first occurrence for each person_id\n",
        "diab_neuro_unique <- diabetic_neuro_dataset %>%\n",
        "  arrange(person_id, condition_start_datetime) %>%  # Sort by person_id and earliest date\n",
        "  group_by(person_id) %>%\n",
        "  slice(1) %>%   # Select the first occurrence per person (earliest date)\n",
        "  ungroup()\n",
        "dim(diab_neuro_unique)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vP_fCTiZMj2v"
      },
      "outputs": [],
      "source": [
        "# We are interestd in getting only the earliest dates of diabetes or diabetic neuropathy occurrence\n",
        "\n",
        "# Ensure dates are in proper datetime format\n",
        "diabetes_dataset <- diabetes_dataset %>%\n",
        "  mutate(condition_start_datetime = as.POSIXct(condition_start_datetime, format=\"%Y-%m-%d %H:%M:%S\", tz=\"UTC\"))\n",
        "\n",
        "diabetic_neuro_dataset <- diabetic_neuro_dataset %>%\n",
        "  mutate(condition_start_datetime = as.POSIXct(condition_start_datetime, format=\"%Y-%m-%d %H:%M:%S\", tz=\"UTC\"))\n",
        "\n",
        "# Get the earliest diabetes diagnosis per person\n",
        "earliest_diabetes <- diabetes_dataset %>%\n",
        "  group_by(person_id) %>%\n",
        "  summarise(first_diabetes_date = min(condition_start_datetime, na.rm = TRUE))\n",
        "\n",
        "# Get the earliest neuropathy diagnosis per person\n",
        "earliest_neuropathy <- diabetic_neuro_dataset %>%\n",
        "  group_by(person_id) %>%\n",
        "  summarise(first_neuro_date = min(condition_start_datetime, na.rm = TRUE))\n",
        "\n",
        "# Merge the two datasets to compare diagnosis dates\n",
        "filtered_diabetic_neuro <- earliest_neuropathy %>%\n",
        "  inner_join(earliest_diabetes, by = \"person_id\") %>%\n",
        "  filter(first_diabetes_date < first_neuro_date)  # Retain only cases where diabetes precedes neuropathy\n",
        "\n",
        "# Merge back with full neuropathy dataset to keep all details of selected cases\n",
        "final_diabetic_neuro_dataset <- diabetic_neuro_dataset %>%\n",
        "  semi_join(filtered_diabetic_neuro, by = \"person_id\")\n",
        "\n",
        "# Display results\n",
        "dim(final_diabetic_neuro_dataset)  # Check dimensions\n",
        "n_distinct(final_diabetic_neuro_dataset$person_id)  # Check unique individuals\n",
        "head(final_diabetic_neuro_dataset)  # View a sample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3B2rYXv_Mj2v"
      },
      "outputs": [],
      "source": [
        "# Ensure dates are in proper datetime format\n",
        "diabetes_dataset <- diabetes_dataset %>%\n",
        "  mutate(condition_start_datetime = as.POSIXct(condition_start_datetime, format=\"%Y-%m-%d %H:%M:%S\", tz=\"UTC\"))\n",
        "\n",
        "diabetic_neuro_dataset <- diabetic_neuro_dataset %>%\n",
        "  mutate(condition_start_datetime = as.POSIXct(condition_start_datetime, format=\"%Y-%m-%d %H:%M:%S\", tz=\"UTC\"))\n",
        "\n",
        "# Get the earliest diabetes diagnosis per person\n",
        "earliest_diabetes <- diabetes_dataset %>%\n",
        "  group_by(person_id) %>%\n",
        "  summarise(first_diabetes_date = min(condition_start_datetime, na.rm = TRUE))\n",
        "\n",
        "# Get the earliest neuropathy diagnosis per person\n",
        "earliest_neuropathy <- diabetic_neuro_dataset %>%\n",
        "  group_by(person_id) %>%\n",
        "  summarise(first_neuro_date = min(condition_start_datetime, na.rm = TRUE))\n",
        "\n",
        "# Merge the two datasets to compare diagnosis dates\n",
        "merged_dates <- earliest_neuropathy %>%\n",
        "  left_join(earliest_diabetes, by = \"person_id\")\n",
        "\n",
        "# **Included data:** Individuals where diabetes diagnosis precedes neuropathy\n",
        "included_patients <- merged_dates %>%\n",
        "  filter(first_diabetes_date < first_neuro_date) %>%\n",
        "  select(person_id)\n",
        "\n",
        "# **Excluded data:** Individuals where diabetes does not precede neuropathy or no diabetes record exists\n",
        "excluded_patients <- merged_dates %>%\n",
        "  filter(is.na(first_diabetes_date) | first_diabetes_date >= first_neuro_date) %>%\n",
        "  select(person_id)\n",
        "\n",
        "# Merge back to get full dataset details\n",
        "included_diabetic_neuro_dataset <- diabetic_neuro_dataset %>%\n",
        "  semi_join(included_patients, by = \"person_id\")\n",
        "\n",
        "excluded_diabetic_neuro_dataset <- diabetic_neuro_dataset %>%\n",
        "  semi_join(excluded_patients, by = \"person_id\")\n",
        "\n",
        "# Check dataset dimensions\n",
        "dim(included_diabetic_neuro_dataset)  # Retained dataset\n",
        "n_distinct(included_diabetic_neuro_dataset$person_id)  # Unique individuals in included dataset\n",
        "\n",
        "dim(excluded_diabetic_neuro_dataset)  # Excluded dataset\n",
        "n_distinct(excluded_diabetic_neuro_dataset$person_id)  # Unique individuals in excluded dataset\n",
        "\n",
        "# **Save both datasets as CSV files**\n",
        "write.csv(included_diabetic_neuro_dataset, \"included_diabetic_neuro.csv\", row.names = FALSE)\n",
        "write.csv(excluded_diabetic_neuro_dataset, \"excluded_diabetic_neuro.csv\", row.names = FALSE)\n",
        "\n",
        "# Display sample of included and excluded datasets\n",
        "head(included_diabetic_neuro_dataset)\n",
        "head(excluded_diabetic_neuro_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bOB4nBfRMj2w"
      },
      "outputs": [],
      "source": [
        "# Check to compare diabetes dates\n",
        "merged_dates"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U30qhvfwMj2w"
      },
      "outputs": [],
      "source": [
        "# filter data by vitamin D deficiency concept IDs (codes checked in the data browser)\n",
        "concept_id_vitD_def <- c(436070, 4300954, 4300955)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZnlPZc55Mj2w"
      },
      "outputs": [],
      "source": [
        "# Filter the dataset for rows where condition_concept_id is in the vitamin D deficiency concept ID list\n",
        "vit_D_def_all_cohorts <- all_conditions_dt %>%\n",
        "  filter(condition_concept_id %in% concept_id_vitD_def)  %>%\n",
        "  select(person_id) %>%\n",
        "  distinct()\n",
        "\n",
        "# Display the first few rows of the filtered dataset\n",
        "head(vit_D_def_all_cohorts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "c6lWkxa-Mj2w"
      },
      "outputs": [],
      "source": [
        "# check the dimension and distinct number of people with vitamin D deficiency\n",
        "dim(vit_D_def_all_cohorts)\n",
        "n_distinct(vit_D_def_all_cohorts$person_id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tf7rm-txMj2w"
      },
      "outputs": [],
      "source": [
        "# # This code adjusts the one above by counting the number of unique participant who have data for each measurement concept id\n",
        "# # Filters only those measurement concept id values where at least 35% of all participants have data\n",
        "# # The total number of participants is determined from the person table\n",
        "\n",
        "# # Update: This counts a participant as long as they have a row for that measurement_concept_id,\n",
        "# # even if the value_as_number is missing (i.e., NA). So for Blood Pressure Panel, Computed blood pressure sys & diastolic,\n",
        "# # Even though the value is missing, the row still exists, so that person is counted toward the 35% threshold.\n",
        "# # That's how those variables \"scaled through.\"\n",
        "\n",
        "# # In other words: we're counting presence of the record, not presence of a meaningful value.\n",
        "\n",
        "# # Start timing\n",
        "tic(\"Total measurement data loading time\")\n",
        "\n",
        "dataset_46654386_measurement_sql <- paste(\"\n",
        "WITH MeasurementCounts AS (\n",
        "    SELECT\n",
        "        measurement_concept_id,\n",
        "        COUNT(DISTINCT person_id) AS participant_count\n",
        "    FROM\n",
        "        `measurement`\n",
        "    WHERE\n",
        "        value_as_number IS NOT NULL\n",
        "    GROUP BY\n",
        "        measurement_concept_id\n",
        "    HAVING\n",
        "        participant_count >= 0.35 * (SELECT COUNT(DISTINCT person_id) FROM `person`) -- 35% threshold\n",
        "    OR measurement_concept_id IN (3022192, 3004410, 3028288, 3028437, 3007070, 3027114)\n",
        ")\n",
        "SELECT\n",
        "    measurement.person_id,\n",
        "    measurement.measurement_concept_id,\n",
        "    m_standard_concept.concept_name AS standard_concept_name,\n",
        "    m_standard_concept.concept_code AS standard_concept_code,\n",
        "    m_standard_concept.vocabulary_id AS standard_vocabulary,\n",
        "    measurement.measurement_datetime,\n",
        "    measurement.measurement_type_concept_id,\n",
        "    m_type.concept_name AS measurement_type_concept_name,\n",
        "    measurement.operator_concept_id,\n",
        "    m_operator.concept_name AS operator_concept_name,\n",
        "    measurement.value_as_number,\n",
        "    measurement.value_as_concept_id,\n",
        "    m_value.concept_name AS value_as_concept_name,\n",
        "    measurement.unit_concept_id,\n",
        "    m_unit.concept_name AS unit_concept_name,\n",
        "    measurement.visit_occurrence_id,\n",
        "    m_visit.concept_name AS visit_occurrence_concept_name,\n",
        "    measurement.measurement_source_value,\n",
        "    measurement.measurement_source_concept_id,\n",
        "    m_source_concept.concept_name AS source_concept_name,\n",
        "    m_source_concept.concept_code AS source_concept_code,\n",
        "    m_source_concept.vocabulary_id AS source_vocabulary,\n",
        "    measurement.unit_source_value,\n",
        "    measurement.value_source_value\n",
        "FROM\n",
        "    `measurement` measurement\n",
        "JOIN\n",
        "    MeasurementCounts mc ON measurement.measurement_concept_id = mc.measurement_concept_id\n",
        "LEFT JOIN\n",
        "    `concept` m_standard_concept ON measurement.measurement_concept_id = m_standard_concept.concept_id\n",
        "LEFT JOIN\n",
        "    `concept` m_type ON measurement.measurement_type_concept_id = m_type.concept_id\n",
        "LEFT JOIN\n",
        "    `concept` m_operator ON measurement.operator_concept_id = m_operator.concept_id\n",
        "LEFT JOIN\n",
        "    `concept` m_value ON measurement.value_as_concept_id = m_value.concept_id\n",
        "LEFT JOIN\n",
        "    `concept` m_unit ON measurement.unit_concept_id = m_unit.concept_id\n",
        "LEFT JOIN\n",
        "    `concept` m_visit ON measurement.visit_occurrence_id = m_visit.concept_id\n",
        "LEFT JOIN\n",
        "    `concept` m_source_concept ON measurement.measurement_source_concept_id = m_source_concept.concept_id\"\n",
        ")\n",
        "\n",
        "# # Formulate a Cloud Storage destination path for the data exported from BigQuery.\n",
        "# # NOTE: By default data exported multiple times on the same day will overwrite older copies.\n",
        "# #       But data exported on a different days will write to a new location so that historical\n",
        "# #       copies can be kept as the dataset definition is changed.\n",
        "\n",
        "measurement_46654386_path <- file.path(\n",
        "  Sys.getenv(\"WORKSPACE_BUCKET\"),\n",
        "  \"bq_exports\",\n",
        "  Sys.getenv(\"OWNER_EMAIL\"),\n",
        "  #strftime(lubridate::now(), \"%Y%m%d\"),  # Comment out this line if you want the export to always overwrite.\n",
        "  \"20250414\",\n",
        "  \"measurement_46654386\",\n",
        "  \"measurement_46654386_*.csv\")\n",
        "message(str_glue('The data will be written to {measurement_46654386_path}. Use this path when reading ',\n",
        "                 'the data into your notebooks in the future.'))\n",
        "\n",
        "# # Perform the query and export the dataset to Cloud Storage as CSV files.\n",
        "# # NOTE: You only need to run `bq_table_save` once. After that, you can\n",
        "# #       just read data from the CSVs in Cloud Storage.\n",
        "bq_table_save(\n",
        "  bq_dataset_query(Sys.getenv(\"WORKSPACE_CDR\"), dataset_46654386_measurement_sql, billing = Sys.getenv(\"GOOGLE_PROJECT\")),\n",
        "  measurement_46654386_path,\n",
        "  destination_format = \"CSV\")\n",
        "toc()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rdBizzjHMj2w"
      },
      "outputs": [],
      "source": [
        "# Read the data directly from Cloud Storage into memory.\n",
        "# NOTE: Alternatively you can `gsutil -m cp {measurement_022625_path}` to copy these files\n",
        "#       to the Jupyter disk.\n",
        "tic(\"Total measurement data loading time\")\n",
        "read_bq_export_measurement <- function(export_path) {\n",
        "  col_types <- cols(\n",
        "    standard_concept_name = col_character(),\n",
        "    standard_concept_code = col_character(),\n",
        "    standard_vocabulary = col_character(),\n",
        "    measurement_type_concept_name = col_character(),\n",
        "    operator_concept_name = col_character(),\n",
        "    value_as_concept_name = col_character(),\n",
        "    unit_concept_name = col_character(),\n",
        "    visit_occurrence_concept_name = col_character(),\n",
        "    source_concept_name = col_character(),\n",
        "    source_concept_code = col_character(),\n",
        "    source_vocabulary = col_character()\n",
        "  )\n",
        "  bind_rows(\n",
        "    map(system2('gsutil', args = c('ls', export_path), stdout = TRUE, stderr = TRUE),\n",
        "        function(csv) {\n",
        "          message(str_glue('Loading {csv}.'))\n",
        "          chunk <- read_csv(pipe(str_glue('gsutil cat {csv}')), col_types = col_types, show_col_types = FALSE)\n",
        "          if (is.null(col_types)) {\n",
        "            col_types <- spec(chunk)\n",
        "          }\n",
        "          chunk\n",
        "        }))\n",
        "}\n",
        "\n",
        "\n",
        "dataset_46654386_measurement_df <- read_bq_export_measurement(measurement_46654386_path)\n",
        "\n",
        "dim(dataset_46654386_measurement_df)\n",
        "\n",
        "head(dataset_46654386_measurement_df, 5)\n",
        "toc()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DYw186iaMj2x"
      },
      "outputs": [],
      "source": [
        "# Check the dimension\n",
        "dim(dataset_46654386_measurement_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q0vDU0-1Mj2x"
      },
      "outputs": [],
      "source": [
        "# Rename the measurement data\n",
        "measurement_dt <- dataset_46654386_measurement_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6nqUyPczMj2x"
      },
      "outputs": [],
      "source": [
        "#group data by measurements\n",
        "check <-\n",
        "    measurement_dt %>%\n",
        "    dplyr::group_by(standard_concept_name) %>%\n",
        "    dplyr::summarise(countp = n_distinct(person_id))\n",
        "check"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "id": "ipqTWAdNMj2x"
      },
      "outputs": [],
      "source": [
        "# View first few rows of data\n",
        "head(measurement_dt, 20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "50a1UzQEMj2x"
      },
      "outputs": [],
      "source": [
        "# We would like to see which measurements have multiple unit codes\n",
        "# Identify measurements with inconsistent units (which need harmonization)\n",
        "# Know how many unit concept codes to handle per variable before reshaping or analysis\n",
        "unique_unit_concept_ids <- measurement_dt %>%\n",
        "  dplyr::select(standard_concept_name, unit_concept_name) %>%\n",
        "  distinct() %>%\n",
        "  arrange(standard_concept_name)\n",
        "unique_unit_concept_ids"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oENfzOKmMj2x"
      },
      "outputs": [],
      "source": [
        "# Count the number of distinct person_id values for each unit_concept_id per measurement\n",
        "unit_counts_per_measurement <- measurement_dt %>%\n",
        "  distinct(standard_concept_code, standard_concept_name, person_id, unit_concept_name) %>%\n",
        "  group_by(standard_concept_code, standard_concept_name, unit_concept_name) %>%\n",
        "  summarise(count = n(), .groups = \"drop\") %>%\n",
        "  arrange(standard_concept_name, desc(count))\n",
        "\n",
        "# View top 10 rows\n",
        "head(unit_counts_per_measurement, 10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4RdGFYzoMj2x"
      },
      "outputs": [],
      "source": [
        "# Instead of counts, lets do proportion\n",
        "# Count distinct person_id per unit_concept_name\n",
        "unit_counts_per_measurement <- measurement_dt %>%\n",
        "  distinct(standard_concept_code, standard_concept_name, person_id, unit_concept_name) %>%\n",
        "  group_by(standard_concept_code, standard_concept_name, unit_concept_name) %>%\n",
        "  summarise(count = n(), .groups = \"drop\")\n",
        "\n",
        "# Calculate total counts per measurement\n",
        "total_counts <- unit_counts_per_measurement %>%\n",
        "  group_by(standard_concept_code, standard_concept_name) %>%\n",
        "  summarise(total = sum(count), .groups = \"drop\")\n",
        "\n",
        "# Join back and compute proportions\n",
        "unit_props_per_measurement <- unit_counts_per_measurement %>%\n",
        "  left_join(total_counts, by = c(\"standard_concept_code\", \"standard_concept_name\")) %>%\n",
        "  #mutate(proportion = count / total) %>%\n",
        "mutate(proportion = round(count / total * 100, 1)) %>%\n",
        "  arrange(standard_concept_name, desc(proportion))\n",
        "\n",
        "# View top 10 rows\n",
        "head(unit_props_per_measurement, 10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SZdkg8RyMj2y"
      },
      "outputs": [],
      "source": [
        "# Check the summary counts for each unit concept id\n",
        "range_summary_all <- measurement_dt %>%\n",
        "  group_by(standard_concept_code, standard_concept_name, unit_concept_id, unit_concept_name, unit_source_value) %>%\n",
        "  summarise(\n",
        "    count = n(),\n",
        "    min_value = min(value_as_number, na.rm = TRUE),\n",
        "    max_value = max(value_as_number, na.rm = TRUE),\n",
        "    .groups = \"drop\"\n",
        "  ) %>%\n",
        "  arrange(desc(count))\n",
        "\n",
        "# View top 10\n",
        "head(range_summary_all, 10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0izoy2gyMj2y"
      },
      "outputs": [],
      "source": [
        "# Check through to see number of unique variables we have\n",
        "unique_variables <- measurement_dt %>%\n",
        "  distinct(standard_concept_name) %>%\n",
        "  arrange(standard_concept_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "62YMDxhvMj2y"
      },
      "outputs": [],
      "source": [
        "# View\n",
        "unique_variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "XdpUl8sVMj2y"
      },
      "outputs": [],
      "source": [
        "# create a mapping to change symbols to words - unit standardization\n",
        "unit_lookup <- tibble::tribble(\n",
        "  ~original,                                ~standardized,\n",
        "  \"kg/sq. m\",                               \"kilogram per square meter\",\n",
        "\n",
        "  \"milligram per deciliter calculated\",     \"milligram per deciliter\",\n",
        "  \"mg/dl\",                                  \"milligram per deciliter\",\n",
        "  \"gram per deciliter calculated\",          \"gram per deciliter\",\n",
        "\n",
        "  \"percentage unit\",                        \"percent\",\n",
        "  \"percent hemoglobin\",                     \"percent\",\n",
        "  \"percent hemoglobin a1c\",                 \"percent\",\n",
        "  \"percent total protein\",                  \"percent\",\n",
        "  \"percentage of total\",                    \"percent\",\n",
        "  \"percentage total hemoglobin\",            \"percent\",\n",
        "\n",
        "  \"micro unit per liter\",                   \"microunit per liter\",\n",
        "  \"mU/L\",                                   \"milliunit per liter\",\n",
        "  \"mIU/mL\",                                 \"milli-international unit per liter\",\n",
        "  \"uIU/mL\",                                 \"micro-international unit per milliliter\",\n",
        "  \"IU/L\",                                   \"unit per liter\",\n",
        "  \"minute\",                                 \"per minute\"\n",
        ")\n",
        "unit_lookup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v0dTsfF5Mj2y"
      },
      "outputs": [],
      "source": [
        "# Apply the mapping to your data\n",
        "tic(\"Time used in running this chunk is: \")\n",
        "measurement_normalized <- measurement_dt %>%\n",
        "  mutate(unit_concept_name = tolower(unit_concept_name)) %>%\n",
        "  left_join(unit_lookup, by = c(\"unit_concept_name\" = \"original\")) %>%\n",
        "  mutate(unit_concept_name = coalesce(standardized, unit_concept_name)) %>%\n",
        "  select(-standardized)\n",
        "toc()\n",
        "\n",
        "dim(measurement_normalized)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SlOgrfdcMj2z"
      },
      "outputs": [],
      "source": [
        "tic(\"Time used in running this chunk is: \")\n",
        "\n",
        "# Clean up invalid unit names first\n",
        "measurement_valid_units <- measurement_normalized %>%\n",
        "  filter(!unit_concept_name %in% c(\"na\", \"no matching concept\") & !is.na(unit_concept_name))\n",
        "\n",
        "# Count how many times each unit appears per measurement\n",
        "unit_counts <- measurement_valid_units %>%\n",
        "  filter(!is.na(unit_concept_name)) %>%\n",
        "  group_by(standard_concept_name, unit_concept_name) %>%\n",
        "  summarise(n = n(), .groups = \"drop\")\n",
        "\n",
        "# For each biomarker, find the most common unit count\n",
        "unit_thresholds <- unit_counts %>%\n",
        "  group_by(standard_concept_name) %>%\n",
        "  summarise(\n",
        "    max_count = max(n),\n",
        "    .groups = \"drop\"\n",
        "  )\n",
        "toc()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "50AOgGEQMj2z"
      },
      "outputs": [],
      "source": [
        "tic(\"Time used in running this chunk is: \")\n",
        "\n",
        "# Join and calculate 10% threshold, keep only acceptable units\n",
        "unit_counts_filtered <- unit_counts %>%\n",
        "  inner_join(unit_thresholds, by = \"standard_concept_name\") %>%\n",
        "  mutate(threshold = 0.1 * max_count) %>%\n",
        "  filter(n >= threshold) %>%\n",
        "  select(standard_concept_name, unit_concept_name)\n",
        "\n",
        "# Filter original dataset to keep only valid units\n",
        "measurement_filtered <- measurement_valid_units %>%\n",
        "  inner_join(unit_counts_filtered, by = c(\"standard_concept_name\", \"unit_concept_name\"))\n",
        "toc()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "oSo0D7xaMj2z"
      },
      "outputs": [],
      "source": [
        "# check the dimension and distinct number of people in the measurements data\n",
        "dim(measurement_filtered);n_distinct(measurement_filtered$person_id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "J2a-_UBfMj2z"
      },
      "outputs": [],
      "source": [
        "# View the data structure\n",
        "glimpse(measurement_filtered)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oEHBHcz0Mj2z"
      },
      "outputs": [],
      "source": [
        "# The next chunk to run is below.\n",
        "# This part was to verify the distribution of the different units coming from BMI, for example."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r23ZhOI0Mj20"
      },
      "outputs": [],
      "source": [
        "# # I want to see if the BMI variable that is in 2 different units have people who have values for both units\n",
        "# # Filter for BMI records\n",
        "# bmi_data <- measurement_filtered %>%\n",
        "#   filter(standard_concept_name == \"Body mass index (BMI) [Ratio]\")\n",
        "# # Count unique units per person\n",
        "# bmi_unit_check <- bmi_data %>%\n",
        "#   group_by(person_id) %>%\n",
        "#   summarize(num_units = n_distinct(unit_concept_name),\n",
        "#             units = paste(unique(unit_concept_name), collapse = \", \")) %>%\n",
        "#   filter(num_units > 1)\n",
        "# #view conflicting records\n",
        "# View(bmi_unit_check)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VlbS23R5Mj20"
      },
      "outputs": [],
      "source": [
        "# #Get Full Records for These People\n",
        "# conflict_ids <- bmi_unit_check$person_id\n",
        "\n",
        "# bmi_conflicting_rows <- bmi_data %>%\n",
        "#   filter(person_id %in% conflict_ids) %>%\n",
        "#   arrange(person_id, measurement_datetime)\n",
        "\n",
        "# View(bmi_conflicting_rows)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NVZNXCErMj20"
      },
      "outputs": [],
      "source": [
        "# colnames(bmi_conflicting_rows)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XWHp1Y7-Mj20"
      },
      "outputs": [],
      "source": [
        "# # Now, I want to check for people who have data for only ratio, and not kilogram per square metter\n",
        "# # Group and summarize by person\n",
        "# bmi_unit_summary <- bmi_data %>%\n",
        "#   group_by(person_id) %>%\n",
        "#   summarize(units = unique(unit_concept_name)) %>%\n",
        "#   unnest(units) %>%\n",
        "#   distinct()\n",
        "\n",
        "# # Find those who only have \"ratio\"\n",
        "# # Count units per person\n",
        "# bmi_unit_count <- bmi_data %>%\n",
        "#   group_by(person_id) %>%\n",
        "#   summarize(all_units = list(unique(unit_concept_name))) %>%\n",
        "#   mutate(\n",
        "#     only_ratio = map_lgl(all_units, ~ all(.x == \"ratio\")),\n",
        "#     includes_kgm2 = map_lgl(all_units, ~ \"kilogram per square meter\" %in% .x)\n",
        "#   ) %>%\n",
        "#   filter(only_ratio == TRUE & includes_kgm2 == FALSE)\n",
        "\n",
        "# # Get full rows for these people\n",
        "# only_ratio_ids <- bmi_unit_count$person_id\n",
        "\n",
        "# bmi_ratio_only <- bmi_data %>%\n",
        "#   filter(person_id %in% only_ratio_ids)\n",
        "\n",
        "# View(bmi_ratio_only)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-hllGuzAMj20"
      },
      "outputs": [],
      "source": [
        "# # Lets confirm that \"ratio\" values look like real BMI:\n",
        "# summary(bmi_data %>% filter(unit_concept_name == \"ratio\") %>% pull(value_as_number))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NcVE4jWbMj20"
      },
      "outputs": [],
      "source": [
        "# Some people have values for both kilogram per square meter and ratio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "id": "toeJAHS8Mj20"
      },
      "outputs": [],
      "source": [
        "# # Create a Summary Table of Units per Measurement\n",
        "# unit_summary2 <- measurement_filtered %>%\n",
        "#   group_by(standard_concept_name, unit_concept_name) %>%\n",
        "#   summarize(\n",
        "#     count = n(),\n",
        "#     non_missing = sum(!is.na(value_as_number)),\n",
        "#     missing_count = sum(is.na(value_as_number)),\n",
        "#     mean = mean(value_as_number, na.rm = TRUE),\n",
        "#     sd = sd(value_as_number, na.rm = TRUE),\n",
        "#     min_value = min(value_as_number, na.rm = TRUE),\n",
        "#     max_value = max(value_as_number, na.rm = TRUE),\n",
        "#     median_value = median(value_as_number, na.rm = TRUE),\n",
        "#     #over_100k = sum(value_as_number > 100000, na.rm = TRUE),\n",
        "#     .groups = \"drop\"\n",
        "#   ) %>%\n",
        "#   arrange(standard_concept_name, desc(count))\n",
        "\n",
        "# # View or write to file\n",
        "# View(unit_summary2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b2vJV336Mj21"
      },
      "outputs": [],
      "source": [
        "# # Filter unit_summary for One Biomarker\n",
        "# # Choose a single biomarker to inspect\n",
        "# biomarker_name <- \"Cholesterol in LDL [Mass/volume] in Serum or Plasma\"\n",
        "\n",
        "# # Filter unit summary for this biomarker\n",
        "# albumin_units <- unit_summary2 %>%\n",
        "#   filter(standard_concept_name == biomarker_name) %>%\n",
        "#   arrange(desc(count))\n",
        "\n",
        "# # View the summary of units used\n",
        "# View(albumin_units)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "bW1Jrjk6Mj21"
      },
      "outputs": [],
      "source": [
        "# # Filter unit_summary for One Biomarker\n",
        "# # Choose a single biomarker to inspect\n",
        "# biomarker_name <- \"Body mass index (BMI) [Ratio]\"\n",
        "\n",
        "# # Filter unit summary for this biomarker\n",
        "# var_units <- unit_summary2 %>%\n",
        "#   filter(standard_concept_name == biomarker_name) %>%\n",
        "#   arrange(desc(count))\n",
        "\n",
        "# # View the summary of units used\n",
        "# View(var_units)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "ysmKXOgYMj21"
      },
      "outputs": [],
      "source": [
        "# # Plotting BMI Distributions\n",
        "# # # Filter extreme values to make plot more interpretable\n",
        "# # bmi_clean <- bmi_data %>%\n",
        "# #   filter(unit_concept_name %in% c(\"kilogram per square meter\", \"ratio\")) %>%\n",
        "# #   filter(value_as_number > 5, value_as_number < 100)\n",
        "\n",
        "# # No filtering  include all values for selected units\n",
        "# bmi_all <- bmi_data %>%\n",
        "#   filter(unit_concept_name %in% c(\"kilogram per square meter\", \"ratio\"))\n",
        "\n",
        "# # Plot distribution\n",
        "# ggplot(bmi_all, aes(x = value_as_number, fill = unit_concept_name)) +\n",
        "#   geom_density(alpha = 0.5) +\n",
        "#   scale_x_log10() +\n",
        "#   labs(\n",
        "#     title = \"BMI Value Distribution by Unit Type (Log Scale)\",\n",
        "#     x = \"BMI Value (log 10 scale)\",\n",
        "#     y = \"Density\",\n",
        "#     fill = \"Unit Type\"\n",
        "#   ) +\n",
        "#   theme_minimal()\n",
        "\n",
        "# #compare them side by side\n",
        "# ggplot(bmi_all, aes(x = value_as_number)) +\n",
        "#   geom_density(fill = \"steelblue\", alpha = 0.6) +\n",
        "#   facet_wrap(~ unit_concept_name, scales = \"free\") +\n",
        "#   labs(title = \"BMI Distribution per Unit\", x = \"BMI\", y = \"Density\") +\n",
        "#   theme_minimal()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yhH9OMVSMj21"
      },
      "outputs": [],
      "source": [
        "# # If we exclude outliers using different methods, what are the data ranges?\n",
        "# # Compute 1st99th percentile range\n",
        "# bmi_percentile_summary <- bmi_data %>%\n",
        "#   filter(unit_concept_name %in% c(\"kilogram per square meter\", \"ratio\")) %>%\n",
        "#   group_by(unit_concept_name) %>%\n",
        "#   summarize(\n",
        "#     p1 = quantile(value_as_number, 0.01, na.rm = TRUE),\n",
        "#     p99 = quantile(value_as_number, 0.99, na.rm = TRUE),\n",
        "#     .groups = \"drop\"\n",
        "#   )\n",
        "# print(bmi_percentile_summary)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xtZmCOLsMj21"
      },
      "outputs": [],
      "source": [
        "# # - value_as_number: BMI values\n",
        "# # - unit_concept_name: Unit type (\"kilogram per square meter\", \"ratio\", etc.)\n",
        "\n",
        "# # Define percentiles to compute\n",
        "# percentiles <- c(0.1, 0.5, 99.5, 99.9)\n",
        "\n",
        "# # Compute percentiles for each unit\n",
        "# bmi_percentiles <- bmi_data %>%\n",
        "#   filter(unit_concept_name %in% c(\"kilogram per square meter\", \"ratio\")) %>%\n",
        "#   group_by(unit_concept_name) %>%\n",
        "#   summarize(across(\n",
        "#     .cols = value_as_number,\n",
        "#     .fns = list(\n",
        "#       `0.1th` = ~ quantile(.x, probs = 0.001, na.rm = TRUE),\n",
        "#       `0.5th` = ~ quantile(.x, probs = 0.005, na.rm = TRUE),\n",
        "#       `99.5th` = ~ quantile(.x, probs = 0.995, na.rm = TRUE),\n",
        "#       `99.9th` = ~ quantile(.x, probs = 0.999, na.rm = TRUE)\n",
        "#     ),\n",
        "#     .names = \"{.fn}\"\n",
        "#   ))\n",
        "\n",
        "# print(bmi_percentiles)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WmOW4GrQMj21"
      },
      "outputs": [],
      "source": [
        "# # Compute IQR-based range\n",
        "# bmi_iqr_summary <- bmi_data %>%\n",
        "#   filter(unit_concept_name %in% c(\"kilogram per square meter\", \"ratio\")) %>%\n",
        "#   group_by(unit_concept_name) %>%\n",
        "#   summarize(\n",
        "#     Q1 = quantile(value_as_number, 0.25, na.rm = TRUE),\n",
        "#     Q3 = quantile(value_as_number, 0.75, na.rm = TRUE),\n",
        "#     IQR = Q3 - Q1,\n",
        "#     lower_bound = Q1 - 1.5 * IQR,\n",
        "#     upper_bound = Q3 + 1.5 * IQR,\n",
        "#     .groups = \"drop\"\n",
        "#   )\n",
        "# print(bmi_iqr_summary)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t1IW5EWJMj21"
      },
      "outputs": [],
      "source": [
        "# Now, we are no longer recoding the \"ratio\" unit\n",
        "# Exclude BMI values with 'ratio' as the unit, as it is obvious they are from different population\n",
        "measurement_filtered_again <- measurement_filtered %>%\n",
        "  filter(!(standard_concept_name == \"Body mass index (BMI) [Ratio]\" & unit_concept_name == \"ratio\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JkLAZ8jLMj21"
      },
      "outputs": [],
      "source": [
        "# check the dimensionof the remaining measurement data\n",
        "dim(measurement_filtered_again)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "38AAa7g4Mj22"
      },
      "outputs": [],
      "source": [
        "# Since we have decided not to concern ourself with the ratio unit for BMI\n",
        "# Let us rename the measurement_filtered_again as measurement_final, so that we can continue our operation on the data\n",
        "measurement_final <- measurement_filtered_again"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0KJAPdbPMj22"
      },
      "outputs": [],
      "source": [
        "# Now to count the distinct number of rows lost in the unit harmonization\n",
        "# We have to count per person per variable\n",
        "# Now compute data loss per variable\n",
        "pre_counts <- measurement_valid_units %>%\n",
        "  group_by(standard_concept_name) %>%\n",
        "  summarise(n_before = n(), .groups = \"drop\")\n",
        "\n",
        "post_counts <- measurement_filtered_again %>%\n",
        "  group_by(standard_concept_name) %>%\n",
        "  summarise(n_after = n(), .groups = \"drop\")\n",
        "\n",
        "# Count distinct person_id before harmonization\n",
        "pre_persons <- measurement_valid_units %>%\n",
        "  distinct(standard_concept_name, person_id) %>%\n",
        "  group_by(standard_concept_name) %>%\n",
        "  summarise(distinct_before = n(), .groups = \"drop\")\n",
        "\n",
        "# Count distinct person_id after harmonization\n",
        "post_persons <- measurement_filtered_again %>%\n",
        "  distinct(standard_concept_name, person_id) %>%\n",
        "  group_by(standard_concept_name) %>%\n",
        "  summarise(distinct_after = n(), .groups = \"drop\")\n",
        "\n",
        "# Join all together\n",
        "unit_loss_summary <- pre_counts %>%\n",
        "  left_join(post_counts, by = \"standard_concept_name\") %>%\n",
        "  left_join(pre_persons,  by = \"standard_concept_name\") %>%\n",
        "  left_join(post_persons, by = \"standard_concept_name\") %>%\n",
        "  mutate(\n",
        "    n_after = replace_na(n_after, 0),\n",
        "    distinct_after = replace_na(distinct_after, 0),\n",
        "    n_lost = n_before - n_after,\n",
        "    pct_lost = round((n_lost / n_before) * 100, 2),\n",
        "    distinct_lost = distinct_before - distinct_after\n",
        "  ) %>%\n",
        "  arrange(desc(n_lost))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "yobqsA8HMj22"
      },
      "outputs": [],
      "source": [
        "# View data\n",
        "unit_loss_summary\n",
        "#write.csv(unit_loss_summary, \"before_vs_after_unit_harmonization.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "MANi4xiYMj22"
      },
      "outputs": [],
      "source": [
        "# Filter out people with pre-diabetic conditions\n",
        "diabetes_dataset_clean <- diabetes_dataset %>%\n",
        "  filter(!person_id %in% pre_diabetes_conditions$person_id#,\n",
        "         #!person_id %in% statin_data$person_id\n",
        "        )\n",
        "n_distinct(diabetes_dataset_clean$person_id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mCEqwbb1Mj22"
      },
      "outputs": [],
      "source": [
        "# loop through every unique measurement variable in standard_concept_name to check the\n",
        "# time periods between the measurement dates and the diabetes onset date\n",
        "\n",
        "# Get list of all unique measurement names\n",
        "measurement_names <- unique(measurement_final$standard_concept_name)\n",
        "\n",
        "# Define a function to process each measurement type\n",
        "process_measurement <- function(measure_name) {\n",
        "  var_filtered <- measurement_final %>%\n",
        "    filter(standard_concept_name == measure_name) %>%\n",
        "    mutate(\n",
        "      measurement_date = as.Date(measurement_datetime),\n",
        "      var_name = make.names(measure_name)  # safe column names\n",
        "    ) %>%\n",
        "    select(person_id, measurement_date, num_value = value_as_number, var_name)\n",
        "\n",
        "  vars_with_onset <- var_filtered %>%\n",
        "    inner_join(diabetes_onset, by = \"person_id\") %>%\n",
        "    mutate(\n",
        "      days_diff = as.numeric(difftime(measurement_date, diabetes_onset_date, units = \"days\")),\n",
        "      weeks_diff = days_diff / 7,\n",
        "      months_diff = days_diff / 30.44  # average days per month\n",
        "    ) %>%\n",
        "    group_by(person_id, var_name) %>%\n",
        "    slice_min(order_by = abs(days_diff), n = 1, with_ties = FALSE) %>%\n",
        "    ungroup()\n",
        "\n",
        "  return(vars_with_onset)\n",
        "}\n",
        "\n",
        "# Apply the function to each measurement and combine results\n",
        "tic(\"Time used in running this chunk is: \")\n",
        "all_measurements_diff <- map_dfr(measurement_names, process_measurement)\n",
        "toc()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "id": "KbHoCaQ2Mj22"
      },
      "outputs": [],
      "source": [
        "# View data - this contains the calculation of differences in the date of diabetes onset and the closest\n",
        "# measurement dates to it by days, weeks and months\n",
        "all_measurements_diff"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nixXfEIeMj22"
      },
      "outputs": [],
      "source": [
        "# Ensure datetime and onset date are Date objects\n",
        "measurement_with_closest_date <- measurement_filtered_again %>%\n",
        "  mutate(measurement_date = as.Date(measurement_datetime))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7uSGOegOMj22"
      },
      "outputs": [],
      "source": [
        "# check the dimension of the diabetes onset\n",
        "dim(diabetes_onset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PKDLSysTMj23"
      },
      "outputs": [],
      "source": [
        "# Ensure the diabetes onset date is in date format\n",
        "diabetes_onset <- diabetes_onset %>%\n",
        "  mutate(diabetes_onset_date = as.Date(diabetes_onset_date))\n",
        "\n",
        "# Join and calculate time difference\n",
        "merged <- measurement_with_closest_date %>%\n",
        "  inner_join(diabetes_onset, by = \"person_id\") %>%\n",
        "  mutate(\n",
        "    time_diff_days = as.numeric(difftime(measurement_date, diabetes_onset_date, units = \"days\")),\n",
        "    abs_time_diff = abs(time_diff_days)\n",
        "  ) #%>%   # Uncomment this line and the next if you want all to be within one week\n",
        "  # Filter to measurements within 7 days of onset\n",
        "  #filter(abs_time_diff <= 7)\n",
        "\n",
        "\n",
        "# If we want to have the variables in two parts - sensitive to timing and non-sensitive to timing\n",
        "# We run the chunk above with the last two lines commented and proceed with the following\n",
        "# This is becasue we are trying to pick some variables within one week while the others are selected within 6 months\n",
        "\n",
        "# Define variable groups\n",
        "sensitive_vars <- c(\"Glucose\", \"HbA1c\", \"Total cholesterol\", \"Triglyceride\",\n",
        "                    \"Cholesterol in HDL\", \"Cholesterol in LDL\",\n",
        "                    \"Aspartate aminotransferase\", \"Alanine aminotransferase\", \"Leukocytes\")\n",
        "\n",
        "# Filter separately by timing window\n",
        "\n",
        "# Sensitive: within 7 days\n",
        "sensitive_selection <- merged %>%\n",
        "  filter(standard_concept_name %in% sensitive_vars, abs_time_diff <= 7) %>%\n",
        "  group_by(person_id, standard_concept_name) %>%\n",
        "  slice_min(order_by = abs_time_diff, n = 1, with_ties = FALSE) %>%\n",
        "  ungroup()\n",
        "\n",
        "# Less sensitive: within 180 days\n",
        "less_sensitive_selection <- merged %>%\n",
        "  filter(!(standard_concept_name %in% sensitive_vars), abs_time_diff <= 180) %>%\n",
        "  group_by(person_id, standard_concept_name) %>%\n",
        "  slice_min(order_by = abs_time_diff, n = 1, with_ties = FALSE) %>%\n",
        "  ungroup()\n",
        "\n",
        "# Combine both\n",
        "final_selection <- bind_rows(sensitive_selection, less_sensitive_selection) %>%\n",
        "  dplyr::select(person_id, standard_concept_name, value_as_number, measurement_date, diabetes_onset_date)  # Add unit_concept_name if needed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cvl5SA-gMj23"
      },
      "outputs": [],
      "source": [
        "# View data\n",
        "final_selection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "Il-Nt-ppMj23"
      },
      "outputs": [],
      "source": [
        "# This means they had some measurements, but none within the allowed:\n",
        "\n",
        "#     7 days (for sensitive variables), or\n",
        "\n",
        "#     180 days (for less-sensitive variables).\n",
        "\n",
        "# Even if a participant has measurements, all their records might fall outside the 7 days or 180 days windows.\n",
        "# Participants in merged but excluded due to timing filters\n",
        "n_distinct(merged$person_id) - n_distinct(final_selection$person_id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DZCQT1YwMj23"
      },
      "outputs": [],
      "source": [
        "# The remaining 6923 - 6842 = 81 participants\n",
        "\n",
        "# These participants are in diabetes_onset but not in measurement_with_closest_date, so they didnt even make it into merged.\n",
        "\n",
        "setdiff(diabetes_onset$person_id, measurement_with_closest_date$person_id) %>% length()  # Should be 81"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PuJ0-fxeMj24"
      },
      "outputs": [],
      "source": [
        "# check the dimension and distinct number of people\n",
        "dim(final_selection)\n",
        "n_distinct(final_selection$person_id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "48osNK6aMj24"
      },
      "outputs": [],
      "source": [
        "# View data\n",
        "final_selection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X9U6oOOPMj24"
      },
      "outputs": [],
      "source": [
        "# To ensure one row per person, you must pre-aggregate or filter the dataset before pivoting.\n",
        "# Let's keep only the row closest to the diabetes onset date per test per person.\n",
        "\n",
        "# Keep only the closest measurement per person and concept\n",
        "group_filtered <- final_selection %>%\n",
        "  mutate(days_diff = abs(as.numeric(difftime(measurement_date, diabetes_onset_date, units = \"days\")))) %>%\n",
        "  group_by(person_id, standard_concept_name) %>%\n",
        "  slice_min(order_by = days_diff, n = 1, with_ties = FALSE) %>%\n",
        "  ungroup()\n",
        "\n",
        "# Create a lookup table for unique diabetes onset date per person\n",
        "# Add diabetes_onset_date back after pivoting\n",
        "onset_lookup <- group_filtered %>%\n",
        "  select(person_id, diabetes_onset_date) %>%\n",
        "  distinct()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D-RAn1pbMj24"
      },
      "outputs": [],
      "source": [
        "# View data\n",
        "group_filtered"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rBAjnSQ-Mj24"
      },
      "outputs": [],
      "source": [
        "# Let's extract just the ID, biomarker name, and the unit information into a new, smaller table.\n",
        "\n",
        "unit_table <- group2 %>%\n",
        "  select(person_id, standard_concept_name, unit_concept_name)\n",
        "unit_table"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "u2ZPZC2sMj24"
      },
      "outputs": [],
      "source": [
        "# Reshape the new dataframe that includes the units from long to wide - it contains different units per variable\n",
        "tic(\"Time used in running this chunk is: \")\n",
        "wide_group <- pivot_wider(group_filtered[!is.na(group_filtered$value_as_number),]\n",
        "                              , id_cols = person_id, names_from = standard_concept_name, values_from = value_as_number) %>%\n",
        "  left_join(onset_lookup, by = \"person_id\")\n",
        "toc()\n",
        "# Display the first few rows of the wide dataframe\n",
        "dim(wide_group)\n",
        "head(wide_group)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "MKixsYggMj25"
      },
      "outputs": [],
      "source": [
        "# sort(colSums(!is.na(wide_group)), decreasing = TRUE)\n",
        "# Count non-NA values per column and convert to data frame\n",
        "# Properly convert the named vector to a data frame\n",
        "na_counts_df <- colSums(!is.na(wide_group)) %>%\n",
        "  sort(decreasing = TRUE) %>%\n",
        "  as.data.frame() %>%\n",
        "  rownames_to_column(var = \"variable\") %>%\n",
        "  rename(non_missing_count = \".\")\n",
        "\n",
        "# View the result\n",
        "na_counts_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eVOPEJXXMj25"
      },
      "outputs": [],
      "source": [
        "#check if one row is the same as one participant\n",
        "# we need one unique person_id on one row\n",
        "count_rows_and_pid <- function(df){\n",
        "  n_pid = n_distinct(df$person_id)\n",
        "  nrow = nrow(df)\n",
        "\n",
        "  print(paste0(\"N participants: \", n_pid))\n",
        "\n",
        "  print(paste0(\"N row: \", nrow))\n",
        "}\n",
        "count_rows_and_pid(wide_group)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oFHougbKMj25"
      },
      "outputs": [],
      "source": [
        "# check the dimension of the data in each domain\n",
        "# person data\n",
        "dim(person_dt)\n",
        "#conditions data\n",
        "dim(diabetes_dataset_unique)\n",
        "dim(final_diabetic_neuro_dataset)\n",
        "# measurement data\n",
        "dim(wide_group)\n",
        "# conditions data\n",
        "dim(vit_D_def_all_cohorts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GY3ddXeFMj25"
      },
      "outputs": [],
      "source": [
        "# Total number of people in the dataset\n",
        "n_distinct(final_diabetic_neuro_dataset$person_id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xarBBnuwMj25"
      },
      "outputs": [],
      "source": [
        "# Total number of Prediabetic people in the data should be excluded from our final dataset\n",
        "prediabetic_persons <- all_conditions_dt %>%\n",
        "  filter(condition_concept_id %in% c(37018196, 44808385)) %>%\n",
        "  select(person_id) %>%\n",
        "  distinct()\n",
        "dim(prediabetic_persons)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E0PxUwXpMj25"
      },
      "outputs": [],
      "source": [
        "# Remove prediabetic individuals from persons and measurements data\n",
        "# prediabetics had already been removed from the diabetic and the diabetic neuropathy group\n",
        "\n",
        "persons_filtered <- person_dt %>%\n",
        "  filter(!person_id %in% prediabetic_persons$person_id)\n",
        "#measurements_filtered <- wide_group_with_ldl_values %>% #use measurement_data here if you dont want the different units\n",
        "measurements_filtered <- wide_group %>%\n",
        "  filter(!person_id %in% prediabetic_persons$person_id)\n",
        "vit_D_def_all_cohorts_filtered <- vit_D_def_all_cohorts %>%\n",
        "  filter(!person_id %in% prediabetic_persons$person_id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "15vSZ3XlMj26"
      },
      "outputs": [],
      "source": [
        "# Ascertain that the prediabetic patients are not also included in your diabetic cohort\n",
        "diabetes_dataset_unique_filtered <- diabetes_dataset_unique %>%\n",
        "    filter(!person_id %in% prediabetic_persons$person_id)#,\n",
        "           #!person_id %in% statin_data$person_id)\n",
        "dim(diabetes_dataset_unique_filtered)\n",
        "\n",
        "# Do same for diabetic neuropathy\n",
        "diab_neuro_unique_filtered <- final_diabetic_neuro_dataset %>% #diab_neuro_unique %>%\n",
        "    filter(!person_id %in% prediabetic_persons$person_id)\n",
        "dim(diab_neuro_unique_filtered)\n",
        "n_distinct(diab_neuro_unique_filtered$person_id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QTPp3v4qMj26"
      },
      "outputs": [],
      "source": [
        "# check the dimension of the data in each domain again\n",
        "dim(persons_filtered)\n",
        "dim(diabetes_dataset_unique_filtered)\n",
        "dim(diab_neuro_unique_filtered)\n",
        "dim(wide_group)\n",
        "dim(vit_D_def_all_cohorts_filtered)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l9tNWCeaMj26"
      },
      "outputs": [],
      "source": [
        "# check the distinct number of people with diabetic neuropathy\n",
        "n_distinct(diab_neuro_unique_filtered$person_id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "odybFmcXMj26"
      },
      "outputs": [],
      "source": [
        "# # Merge Person Data, Conditions Data, and Measurement Data\n",
        "\n",
        "master_dataset <- persons_filtered %>%\n",
        "  #mutate(diabetes = ifelse(person_id %in% diabetes_dataset_unique_filtered$person_id, \"Yes\", \"No\"),\n",
        "    mutate(diabetes = ifelse(person_id %in% wide_group$person_id, \"Yes\", \"No\"),\n",
        "         diabetic_neuropathy = ifelse(person_id %in% diab_neuro_unique_filtered$person_id, \"Yes\", \"No\"),\n",
        "         vitamin_D_deficiency = ifelse(person_id %in% vit_D_def_all_cohorts_filtered$person_id, \"Yes\", \"No\")) %>%\n",
        "  left_join(wide_group, by = \"person_id\")\n",
        "\n",
        "# Join onset dates to the master dataset\n",
        "master_dataset <- master_dataset %>%\n",
        "  left_join(diabetes_start_dates, by = \"person_id\") %>%\n",
        "  left_join(diab_neuro_start_dates, by = \"person_id\")\n",
        "\n",
        "\n",
        "dim(master_dataset)\n",
        "n_distinct(master_dataset$person_id)\n",
        "head(master_dataset, 20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CHX0g-IpMj27"
      },
      "outputs": [],
      "source": [
        "# Save the data into the google bucket\n",
        "\n",
        "# time the process\n",
        "tic(\"Total saving time\")\n",
        "# write to csv\n",
        "write.csv(master_dataset, file = \"20250719_closest_measurement_to_diabetes_onset_data.csv\", row.names = FALSE)\n",
        "\n",
        "#this is the workspace\n",
        "(WORKSPACE_BUCKET <- Sys.getenv('WORKSPACE_BUCKET'))\n",
        "(USER <- Sys.getenv('OWNER_EMAIL'))\n",
        "# Timestamp to be used\n",
        "(TIMESTAMP <- strftime(now(), '%Y%m%d/%H%M%S'))\n",
        "REPORT_FOLDER <- str_glue('{WORKSPACE_BUCKET}/reports/{USER}')\n",
        "(REPORT_DESTINATION <- str_glue('{REPORT_FOLDER}/{TIMESTAMP}/'))\n",
        "system(str_glue(\n",
        "    'echo {USER} about to save copies of work from {TIMESTAMP} | gsutil cp - {REPORT_DESTINATION}comment.txt 2>&1'),\n",
        "       intern = TRUE)\n",
        "system(str_glue('gsutil cat {REPORT_DESTINATION}comment.txt'), intern = TRUE)\n",
        "\n",
        "#list.files()\n",
        "\n",
        "system(str_glue('gsutil -m cp 20250719_closest_measurement_to_diabetes_onset_data.csv {REPORT_DESTINATION} 2>&1'),\n",
        "       intern = TRUE)\n",
        "toc()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "R",
      "language": "R",
      "name": "ir"
    },
    "language_info": {
      "codemirror_mode": "r",
      "file_extension": ".r",
      "mimetype": "text/x-r-source",
      "name": "R",
      "pygments_lexer": "r",
      "version": "4.5.0"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}